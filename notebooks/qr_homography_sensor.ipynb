{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_light_130.JPG\n",
      "Processing: ../data/test/samples/test_light_130.JPG\n",
      "here\n",
      "Saved YOLO label file: ../data/test/results/cv2_detector//labels/test_light_130.txt\n",
      "Saved annotated image: ../data/test/results/cv2_detector//images/test_light_130_result.jpg\n",
      "test_light_120.JPG\n",
      "Processing: ../data/test/samples/test_light_120.JPG\n",
      "here\n",
      "Saved YOLO label file: ../data/test/results/cv2_detector//labels/test_light_120.txt\n",
      "Saved annotated image: ../data/test/results/cv2_detector//images/test_light_120_result.jpg\n",
      "test_110.JPG\n",
      "Processing: ../data/test/samples/test_110.JPG\n",
      "here\n",
      "Saved YOLO label file: ../data/test/results/cv2_detector//labels/test_110.txt\n",
      "Saved annotated image: ../data/test/results/cv2_detector//images/test_110_result.jpg\n",
      "test_60.JPG\n",
      "Processing: ../data/test/samples/test_60.JPG\n",
      "here\n",
      "Saved YOLO label file: ../data/test/results/cv2_detector//labels/test_60.txt\n",
      "Saved annotated image: ../data/test/results/cv2_detector//images/test_60_result.jpg\n",
      "test_light_60.JPG\n",
      "Processing: ../data/test/samples/test_light_60.JPG\n",
      "here\n",
      "Saved YOLO label file: ../data/test/results/cv2_detector//labels/test_light_60.txt\n",
      "Saved annotated image: ../data/test/results/cv2_detector//images/test_light_60_result.jpg\n",
      "test_light_140.JPG\n",
      "Processing: ../data/test/samples/test_light_140.JPG\n",
      "here\n",
      "Saved YOLO label file: ../data/test/results/cv2_detector//labels/test_light_140.txt\n",
      "Saved annotated image: ../data/test/results/cv2_detector//images/test_light_140_result.jpg\n",
      "test_light_70.JPG\n",
      "Processing: ../data/test/samples/test_light_70.JPG\n",
      "here\n",
      "Saved YOLO label file: ../data/test/results/cv2_detector//labels/test_light_70.txt\n",
      "Saved annotated image: ../data/test/results/cv2_detector//images/test_light_70_result.jpg\n",
      "test_70.JPG\n",
      "Processing: ../data/test/samples/test_70.JPG\n",
      "here\n",
      "Saved YOLO label file: ../data/test/results/cv2_detector//labels/test_70.txt\n",
      "Saved annotated image: ../data/test/results/cv2_detector//images/test_70_result.jpg\n",
      "test_100.JPG\n",
      "Processing: ../data/test/samples/test_100.JPG\n",
      "here\n",
      "Saved YOLO label file: ../data/test/results/cv2_detector//labels/test_100.txt\n",
      "Saved annotated image: ../data/test/results/cv2_detector//images/test_100_result.jpg\n",
      "test_light_80.JPG\n",
      "Processing: ../data/test/samples/test_light_80.JPG\n",
      "here\n",
      "Saved YOLO label file: ../data/test/results/cv2_detector//labels/test_light_80.txt\n",
      "Saved annotated image: ../data/test/results/cv2_detector//images/test_light_80_result.jpg\n",
      "test_130.JPG\n",
      "Processing: ../data/test/samples/test_130.JPG\n",
      "here\n",
      "Saved YOLO label file: ../data/test/results/cv2_detector//labels/test_130.txt\n",
      "Saved annotated image: ../data/test/results/cv2_detector//images/test_130_result.jpg\n",
      "test_80.JPG\n",
      "Processing: ../data/test/samples/test_80.JPG\n",
      "here\n",
      "Saved YOLO label file: ../data/test/results/cv2_detector//labels/test_80.txt\n",
      "Saved annotated image: ../data/test/results/cv2_detector//images/test_80_result.jpg\n",
      "test_120.JPG\n",
      "Processing: ../data/test/samples/test_120.JPG\n",
      "here\n",
      "Saved YOLO label file: ../data/test/results/cv2_detector//labels/test_120.txt\n",
      "Saved annotated image: ../data/test/results/cv2_detector//images/test_120_result.jpg\n",
      "test_90.JPG\n",
      "Processing: ../data/test/samples/test_90.JPG\n",
      "here\n",
      "Saved YOLO label file: ../data/test/results/cv2_detector//labels/test_90.txt\n",
      "Saved annotated image: ../data/test/results/cv2_detector//images/test_90_result.jpg\n",
      "test_light_90.JPG\n",
      "Processing: ../data/test/samples/test_light_90.JPG\n",
      "here\n",
      "Saved YOLO label file: ../data/test/results/cv2_detector//labels/test_light_90.txt\n",
      "Saved annotated image: ../data/test/results/cv2_detector//images/test_light_90_result.jpg\n",
      "test_light_110.JPG\n",
      "Processing: ../data/test/samples/test_light_110.JPG\n",
      "here\n",
      "Saved YOLO label file: ../data/test/results/cv2_detector//labels/test_light_110.txt\n",
      "Saved annotated image: ../data/test/results/cv2_detector//images/test_light_110_result.jpg\n",
      "test_140.JPG\n",
      "Processing: ../data/test/samples/test_140.JPG\n",
      "here\n",
      "Saved YOLO label file: ../data/test/results/cv2_detector//labels/test_140.txt\n",
      "Saved annotated image: ../data/test/results/cv2_detector//images/test_140_result.jpg\n",
      "test_light_100.JPG\n",
      "Processing: ../data/test/samples/test_light_100.JPG\n",
      "here\n",
      "Saved YOLO label file: ../data/test/results/cv2_detector//labels/test_light_100.txt\n",
      "Saved annotated image: ../data/test/results/cv2_detector//images/test_light_100_result.jpg\n"
     ]
    }
   ],
   "source": [
    "def qr_code_detector(image_path, output_dir, save_annotated=True):\n",
    "    \"\"\"\n",
    "    Detect QR codes using OpenCV and save results in YOLO format.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "        output_dir (str): Directory to save results (images and labels).\n",
    "        save_annotated (bool): If True, save the annotated image with QR code detections.\n",
    "    \"\"\"\n",
    "    # Create output directories for images and labels\n",
    "    os.makedirs(f\"{output_dir}/images\", exist_ok=True)\n",
    "    os.makedirs(f\"{output_dir}/labels\", exist_ok=True)\n",
    "    \n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Error: Could not load image at {image_path}\")\n",
    "    h, w = image.shape[:2]\n",
    "    image_name = os.path.splitext(os.path.basename(image_path))[0]  # Extract name without extension\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Initialize QR Code detector\n",
    "    qr_detector = cv2.QRCodeDetector()\n",
    "\n",
    "    # Detect and decode QR codes\n",
    "    data, _, vertices, _ = qr_detector.detectAndDecodeMulti(gray_image)\n",
    "\n",
    "    labels = []  # Store YOLO-format labels\n",
    "    if vertices is not None:\n",
    "        for i, points in enumerate(vertices):\n",
    "            # Calculate bounding box center, width, and height\n",
    "            x_min = points[:, 0].min()\n",
    "            y_min = points[:, 1].min()\n",
    "            x_max = points[:, 0].max()\n",
    "            y_max = points[:, 1].max()\n",
    "\n",
    "            x_center = (x_min + x_max) / 2 / w  # Normalize by image width\n",
    "            y_center = (y_min + y_max) / 2 / h  # Normalize by image height\n",
    "            width = (x_max - x_min) / w         # Normalize width\n",
    "            height = (y_max - y_min) / h        # Normalize height\n",
    "\n",
    "            labels.append([0, x_center, y_center, width, height])  # Assuming class_id = 0 for QR codes\n",
    "\n",
    "            # Draw bounding box on the image\n",
    "            if save_annotated:\n",
    "                points = points.astype(int)\n",
    "                cv2.polylines(image, [points], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "                cv2.putText(image, f\"QR {i}\", tuple(points[0]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "    else:\n",
    "        print(f\"No QR codes detected in {image_path}\")\n",
    "\n",
    "    # Save YOLO labels\n",
    "    label_path = f\"{output_dir}/labels/{image_name}.txt\"\n",
    "    with open(label_path, \"w\") as f:\n",
    "        for label in labels:\n",
    "            f.write(\" \".join(map(str, label)) + \"\\n\")\n",
    "    print(f\"Saved YOLO label file: {label_path}\")\n",
    "\n",
    "    # Save annotated image\n",
    "    if save_annotated:\n",
    "        annotated_image_path = f\"{output_dir}/images/{image_name}_result.jpg\"\n",
    "        cv2.imwrite(annotated_image_path, image)\n",
    "        print(f\"Saved annotated image: {annotated_image_path}\")\n",
    "\n",
    "# Example Usage\n",
    "test_dir = \"../data/test/samples/\"\n",
    "cv2_results_dir = \"../data/test/results/cv2_detector/\"\n",
    "\n",
    "# Run QR code detection and save results for each image in the test directory\n",
    "for filename in os.listdir(test_dir):\n",
    "    if filename.endswith((\".jpg\", \".png\", \".jpeg\",\".JPG\")) and \"out\" not in filename and filename[0] != \".\":\n",
    "        filepath = os.path.join(test_dir, filename)\n",
    "        print(f\"Processing: {filepath}\")\n",
    "        qr_code_detector(filepath, cv2_results_dir, save_annotated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/aq_home/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2024-12-12 Python-3.11.11 torch-2.5.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 1760518 parameters, 0 gradients, 4.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "../data/test/samples/test_light_130.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aq_home/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved annotated image: ../results/yolov5n/images/test_light_130_result.jpg\n",
      "Saved YOLO label file: ../results/yolov5n/labels/test_light_130.txt\n",
      "../data/test/samples/test_light_120.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aq_home/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved annotated image: ../results/yolov5n/images/test_light_120_result.jpg\n",
      "Saved YOLO label file: ../results/yolov5n/labels/test_light_120.txt\n",
      "../data/test/samples/test_110.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aq_home/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved annotated image: ../results/yolov5n/images/test_110_result.jpg\n",
      "Saved YOLO label file: ../results/yolov5n/labels/test_110.txt\n",
      "../data/test/samples/test_60.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aq_home/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved annotated image: ../results/yolov5n/images/test_60_result.jpg\n",
      "Saved YOLO label file: ../results/yolov5n/labels/test_60.txt\n",
      "../data/test/samples/test_light_60.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aq_home/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved annotated image: ../results/yolov5n/images/test_light_60_result.jpg\n",
      "Saved YOLO label file: ../results/yolov5n/labels/test_light_60.txt\n",
      "../data/test/samples/test_light_140.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aq_home/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved annotated image: ../results/yolov5n/images/test_light_140_result.jpg\n",
      "Saved YOLO label file: ../results/yolov5n/labels/test_light_140.txt\n",
      "../data/test/samples/test_light_70.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aq_home/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved annotated image: ../results/yolov5n/images/test_light_70_result.jpg\n",
      "Saved YOLO label file: ../results/yolov5n/labels/test_light_70.txt\n",
      "../data/test/samples/test_70.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aq_home/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved annotated image: ../results/yolov5n/images/test_70_result.jpg\n",
      "Saved YOLO label file: ../results/yolov5n/labels/test_70.txt\n",
      "../data/test/samples/test_100.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aq_home/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved annotated image: ../results/yolov5n/images/test_100_result.jpg\n",
      "Saved YOLO label file: ../results/yolov5n/labels/test_100.txt\n",
      "../data/test/samples/test_light_80.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aq_home/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved annotated image: ../results/yolov5n/images/test_light_80_result.jpg\n",
      "Saved YOLO label file: ../results/yolov5n/labels/test_light_80.txt\n",
      "../data/test/samples/test_130.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aq_home/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved annotated image: ../results/yolov5n/images/test_130_result.jpg\n",
      "Saved YOLO label file: ../results/yolov5n/labels/test_130.txt\n",
      "../data/test/samples/test_80.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aq_home/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved annotated image: ../results/yolov5n/images/test_80_result.jpg\n",
      "Saved YOLO label file: ../results/yolov5n/labels/test_80.txt\n",
      "../data/test/samples/test_120.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aq_home/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved annotated image: ../results/yolov5n/images/test_120_result.jpg\n",
      "Saved YOLO label file: ../results/yolov5n/labels/test_120.txt\n",
      "../data/test/samples/test_90.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aq_home/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved annotated image: ../results/yolov5n/images/test_90_result.jpg\n",
      "Saved YOLO label file: ../results/yolov5n/labels/test_90.txt\n",
      "../data/test/samples/test_light_90.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aq_home/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved annotated image: ../results/yolov5n/images/test_light_90_result.jpg\n",
      "Saved YOLO label file: ../results/yolov5n/labels/test_light_90.txt\n",
      "../data/test/samples/test_light_110.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aq_home/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved annotated image: ../results/yolov5n/images/test_light_110_result.jpg\n",
      "Saved YOLO label file: ../results/yolov5n/labels/test_light_110.txt\n",
      "../data/test/samples/test_140.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aq_home/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved annotated image: ../results/yolov5n/images/test_140_result.jpg\n",
      "Saved YOLO label file: ../results/yolov5n/labels/test_140.txt\n",
      "../data/test/samples/test_light_100.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aq_home/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved annotated image: ../results/yolov5n/images/test_light_100_result.jpg\n",
      "Saved YOLO label file: ../results/yolov5n/labels/test_light_100.txt\n"
     ]
    }
   ],
   "source": [
    "cv2_results_dir = \"../data/test/results/yolov5n\"\n",
    "\n",
    "def save_yolo_results(model, image_path, output_dir):\n",
    "    \"\"\"\n",
    "    Perform inference with YOLOv5 and save the results as annotated images and YOLO labels.\n",
    "\n",
    "    Args:\n",
    "        model: Loaded YOLOv5 model.\n",
    "        image_path (str): Path to the input image.\n",
    "        output_dir (str): Directory to save results (images and labels).\n",
    "    \"\"\"\n",
    "    # Create output directories for images and labels\n",
    "    os.makedirs(f\"{output_dir}/images\", exist_ok=True)\n",
    "    os.makedirs(f\"{output_dir}/labels\", exist_ok=True)\n",
    "    \n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image_name = os.path.splitext(os.path.basename(image_path))[0]  # Extract name without extension\n",
    "    \n",
    "    # Perform inference\n",
    "    results = model(image)\n",
    "\n",
    "    # Save annotated image\n",
    "    rendered_image = results.render()[0]  # Renders the detections\n",
    "    rendered_image = cv2.cvtColor(rendered_image, cv2.COLOR_RGB2BGR)  # Convert to BGR\n",
    "    rendered_image = np.ascontiguousarray(rendered_image, dtype=np.uint8)  # Ensure data type and memory\n",
    "\n",
    "    # Save annotated image\n",
    "    image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    annotated_image_path = f\"{output_dir}/images/{image_name}_result.jpg\"\n",
    "    cv2.imwrite(annotated_image_path, rendered_image)\n",
    "    print(f\"Saved annotated image: {annotated_image_path}\")\n",
    "    \n",
    "    # Save detection labels in YOLO format\n",
    "    label_path = f\"{output_dir}/labels/{image_name}.txt\"\n",
    "    detections = results.pandas().xywh[0]  # Get results as DataFrame\n",
    "    \n",
    "    with open(label_path, \"w\") as f:\n",
    "        for _, row in detections.iterrows():\n",
    "            class_id = row['class']\n",
    "            x_center = row['xcenter'] / image.shape[1]  # Normalize x center\n",
    "            y_center = row['ycenter'] / image.shape[0]  # Normalize y center\n",
    "            width = row['width'] / image.shape[1]       # Normalize width\n",
    "            height = row['height'] / image.shape[0]     # Normalize height\n",
    "            \n",
    "            f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "    \n",
    "    print(f\"Saved YOLO label file: {label_path}\")\n",
    "\n",
    "# Load the model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='../models/yolov5n_best.pt')\n",
    "\n",
    "# Verify the model is loaded\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Input and output paths\n",
    "image_path = '../data/test/test_60.JPG'\n",
    "output_dir = \"../results/yolov5n\"\n",
    "\n",
    "# Run inference and save results\n",
    "for filename in os.listdir(test_dir):\n",
    "    if \"out\" not in filename and filename[0] != \".\":\n",
    "        filepath = os.path.join(test_dir, filename)\n",
    "        print(filepath)\n",
    "        save_yolo_results(model, filepath, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
